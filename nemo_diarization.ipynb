{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import wget\n",
    "from omegaconf import OmegaConf\n",
    "import json\n",
    "from nemo.collections.asr.parts.utils.decoder_timestamps_utils import (\n",
    "    ASRDecoderTimeStamps,\n",
    ")\n",
    "from nemo.collections.asr.parts.utils.diarization_utils import OfflineDiarWithASR\n",
    "from nemo.collections.asr.parts.utils.speaker_utils import rttm_to_labels\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "def read_file(path_to_file):\n",
    "    with open(path_to_file) as f:\n",
    "        contents = f.read().splitlines()\n",
    "    return contents\n",
    "\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "data_dir = os.path.join(ROOT, \"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "EPISODE_TITLE = \"241_-_Computers\"\n",
    "AUDIO_FILENAME = os.path.join(data_dir, f\"{EPISODE_TITLE}.wav\")\n",
    "\n",
    "shutil.copy(os.path.join(ROOT, f\"{EPISODE_TITLE}.wav\"), AUDIO_FILENAME)\n",
    "\n",
    "DOMAIN_TYPE = (\n",
    "    \"meeting\"  # Can be meeting or telephonic based on domain type of the audio file\n",
    ")\n",
    "CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
    "\n",
    "CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
    "\n",
    "if not os.path.exists(os.path.join(data_dir, CONFIG_FILE_NAME)):\n",
    "    CONFIG = wget.download(CONFIG_URL, data_dir)\n",
    "else:\n",
    "    CONFIG = os.path.join(data_dir, CONFIG_FILE_NAME)\n",
    "\n",
    "cfg = OmegaConf.load(CONFIG)\n",
    "\n",
    "# Create a manifest file for input with below format.\n",
    "# {\"audio_filepath\": \"/path/to/audio_file\", \"offset\": 0, \"duration\": null, \"label\": \"infer\", \"text\": \"-\",\n",
    "# \"num_speakers\": null, \"rttm_filepath\": \"/path/to/rttm/file\", \"uem_filepath\"=\"/path/to/uem/filepath\"}\n",
    "\n",
    "meta = {\n",
    "    \"audio_filepath\": AUDIO_FILENAME,\n",
    "    \"offset\": 0,\n",
    "    \"duration\": None,\n",
    "    \"label\": \"infer\",\n",
    "    \"text\": \"-\",\n",
    "    \"num_speakers\": None,\n",
    "    \"rttm_filepath\": None,\n",
    "    \"uem_filepath\": None,\n",
    "}\n",
    "with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
    "    json.dump(meta, fp)\n",
    "    fp.write(\"\\n\")\n",
    "\n",
    "cfg.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
    "\n",
    "pretrained_speaker_model = \"titanet_large\"\n",
    "cfg.diarizer.manifest_filepath = cfg.diarizer.manifest_filepath\n",
    "cfg.diarizer.out_dir = (\n",
    "    data_dir  # Directory to store intermediate files and prediction outputs\n",
    ")\n",
    "cfg.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "cfg.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "\n",
    "# Using Neural VAD and Conformer ASR\n",
    "cfg.diarizer.vad.model_path = \"vad_multilingual_marblenet\"\n",
    "cfg.diarizer.asr.model_path = \"stt_en_conformer_ctc_large\"\n",
    "cfg.diarizer.oracle_vad = False  # ----> Not using oracle VAD\n",
    "cfg.diarizer.asr.parameters.asr_based_vad = False\n",
    "\n",
    "asr_decoder_ts = ASRDecoderTimeStamps(cfg.diarizer)\n",
    "asr_model = asr_decoder_ts.set_asr_model()\n",
    "word_hyp, word_ts_hyp = asr_decoder_ts.run_ASR(asr_model)\n",
    "\n",
    "asr_diar_offline = OfflineDiarWithASR(cfg.diarizer)\n",
    "asr_diar_offline.word_ts_anchor_offset = asr_decoder_ts.word_ts_anchor_offset\n",
    "\n",
    "diar_hyp, diar_score = asr_diar_offline.run_diarization(cfg, word_ts_hyp)\n",
    "# segment timestamps and speaker labels\n",
    "# diar_hyp[EPISODE_TITLE]\n",
    "\n",
    "predicted_speaker_label_rttm_path = f\"{data_dir}/pred_rttms/{EPISODE_TITLE}.rttm\"\n",
    "pred_rttm = read_file(predicted_speaker_label_rttm_path)\n",
    "\n",
    "pred_labels = rttm_to_labels(predicted_speaker_label_rttm_path)\n",
    "\n",
    "trans_info_dict = asr_diar_offline.get_transcript_with_speaker_labels(\n",
    "    diar_hyp, word_hyp, word_ts_hyp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(pred_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_path_to_file = f\"{data_dir}/pred_rttms/{EPISODE_TITLE}.txt\"\n",
    "transcript = read_file(transcription_path_to_file)\n",
    "pp.pprint(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_path_to_file = f\"{data_dir}/pred_rttms/{EPISODE_TITLE}.json\"\n",
    "json_contents = read_file(transcription_path_to_file)\n",
    "pp.pprint(json_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
